"use client";

import Link from "next/link";
import Sidebar from "@/components/Sidebar";
import CodeBlock from "@/components/CodeBlock";
import InfoBox from "@/components/InfoBox";
import Quiz from "@/components/Quiz";
import type { QuizQuestion } from "@/components/Quiz";
import LessonExercises from "@/components/LessonExercises";
import type { LessonExercise } from "@/components/LessonExercises";
import LessonCompleteButton from "@/components/LessonCompleteButton";

const quizQuestions: QuizQuestion[] = [
  {
    question: "Comment acc√©der √† l'event log d'un pipeline DLT ?",
    options: ["SELECT * FROM pipeline_log", "SELECT * FROM event_log('pipeline_name')", "dbutils.pipeline.getLog()", "SHOW LOGS pipeline_name"],
    correctIndex: 1,
    explanation: "La fonction event_log() permet de requ√™ter le journal d'√©v√©nements d'un pipeline DLT.",
  },
  {
    question: "Qui g√®re les clusters d'un pipeline DLT ?",
    options: ["L'utilisateur", "L'administrateur", "DLT g√®re ses propres clusters automatiquement", "Le job scheduler"],
    correctIndex: 2,
    explanation: "DLT cr√©e et g√®re ses propres clusters automatiquement, l'utilisateur n'a pas besoin de les configurer.",
  },
  {
    question: "Quel type d'√©v√©nement contient les m√©triques de qualit√© ?",
    options: ["dataset_definition", "flow_progress", "cluster_status", "maintenance"],
    correctIndex: 1,
    explanation: "Les √©v√©nements flow_progress contiennent les m√©triques de traitement et les r√©sultats des expectations de qualit√©.",
  },
  {
    question: "O√π sont stock√©s les fichiers Delta d'un pipeline DLT ?",
    options: ["Dans /tmp/dlt/", "Dans le r√©pertoire tables/ du storage location du pipeline", "Dans le metastore Hive", "Dans un bucket s√©par√©"],
    correctIndex: 1,
    explanation: "Le storage location contient system/ (event log), tables/ (Delta tables), et autoloader/ (schema tracking).",
  },
  {
    question: "Comment visualiser le DAG d'un pipeline DLT ?",
    options: ["Avec dbutils.pipeline.dag()", "Dans l'interface graphique du pipeline DLT", "Avec SHOW DAG pipeline", "Ce n'est pas possible"],
    correctIndex: 1,
    explanation: "L'interface DLT de Databricks affiche automatiquement le DAG avec les d√©pendances entre les tables.",
  },
];

const exercises: LessonExercise[] = [
  {
    id: "analyser-event-log",
    title: "Analyser l'event log",
    description: "√âcrivez des requ√™tes SQL pour extraire les m√©triques de qualit√©, le nombre de lignes et les √©v√©nements d'erreur depuis l'event log.",
    difficulty: "moyen",
    type: "code",
    prompt: "√âcrivez trois requ√™tes SQL exploitant l'event log d'un pipeline DLT : 1) extraire les m√©triques de qualit√© des expectations, 2) compter le nombre de lignes produites par table, 3) lister les √©v√©nements d'erreur.",
    hints: [
      "Utilisez event_log('pipeline_name') comme source",
      "Filtrez sur event_type = 'flow_progress' pour les m√©triques",
      "Utilisez la notation details:flow_progress.data_quality pour le JSON",
    ],
    solution: {
      code: `-- 1. M√©triques de qualit√© des expectations\nSELECT\n  timestamp,\n  details:flow_progress.data_quality.expectations.name AS contrainte,\n  details:flow_progress.data_quality.expectations.passed_records AS valides,\n  details:flow_progress.data_quality.expectations.failed_records AS invalides\nFROM event_log("my_pipeline")\nWHERE event_type = 'flow_progress'\n  AND details:flow_progress.data_quality IS NOT NULL\nORDER BY timestamp DESC;\n\n-- 2. Nombre de lignes produites par table\nSELECT\n  details:flow_progress.metrics.num_output_rows AS lignes_produites,\n  details:flow_progress.data_quality.expectations.dataset AS table_cible\nFROM event_log("my_pipeline")\nWHERE event_type = 'flow_progress';\n\n-- 3. √âv√©nements d'erreur\nSELECT timestamp, event_type, message\nFROM event_log("my_pipeline")\nWHERE level = 'ERROR'\nORDER BY timestamp DESC;`,
      language: "sql",
      explanation: "L'event log est la source principale pour surveiller un pipeline DLT. Les m√©triques de qualit√© sont dans les √©v√©nements flow_progress, au format JSON dans la colonne details.",
    },
  },
  {
    id: "diagnostiquer-pipeline",
    title: "Diagnostiquer un pipeline",
    description: "Analysez un sc√©nario d'√©chec de pipeline et expliquez comment utiliser l'event log pour trouver la cause racine.",
    difficulty: "difficile",
    type: "reflexion",
    prompt: "Votre pipeline DLT √©choue lors de la mise √† jour de la table Silver. Le DAG montre que la table Bronze est en succ√®s mais Silver est en rouge. Expliquez la d√©marche compl√®te pour diagnostiquer le probl√®me en utilisant l'event log et l'interface DLT.",
    hints: [
      "Commencez par v√©rifier les √©v√©nements d'erreur dans l'event log",
      "V√©rifiez si une expectation FAIL UPDATE a d√©clench√© l'arr√™t",
      "Examinez les m√©triques flow_progress pour la table Silver",
    ],
    solution: {
      explanation: "D√©marche de diagnostic : 1) Consulter le DAG pour identifier la table en √©chec (Silver). 2) Interroger l'event log avec WHERE level = 'ERROR' pour obtenir le message d'erreur exact. 3) V√©rifier si l'√©chec est d√ª √† une expectation FAIL UPDATE en filtrant sur event_type = 'flow_progress' et en examinant data_quality. 4) Si c'est une expectation, identifier les donn√©es invalides dans Bronze. 5) Si c'est une erreur de transformation, examiner le message d'erreur pour corriger la requ√™te SQL/Python. 6) Utiliser Repair Run pour relancer uniquement la table Silver apr√®s correction.",
    },
  },
];

export default function ResultatsPipelinePage() {
  return (
    <div className="flex min-h-[calc(100vh-4rem)]">
      <Sidebar currentPath="/modules/4-2-resultats-pipeline" />

      <main className="flex-1 overflow-y-auto">
        <div className="max-w-4xl mx-auto px-6 py-10 lg:px-10">
          {/* Header */}
          <div className="mb-10">
            <div className="flex items-center gap-3 mb-3">
              <span className="inline-flex items-center px-3 py-1 rounded-full text-xs font-semibold bg-blue-100 text-blue-800">
                Module 4
              </span>
              <span className="text-sm text-[var(--color-text-light)]">
                Le√ßon 4.2
              </span>
            </div>
            <h1 className="text-3xl font-bold text-[var(--color-text)] mb-3">
              R√©sultats du Pipeline
            </h1>
            <p className="text-lg text-[var(--color-text-light)] leading-relaxed">
              Apprenez √† explorer les r√©sultats d&apos;un pipeline Delta Live
              Tables : structure de stockage, event log, m√©triques de qualit√©
              des donn√©es, et outils de surveillance pour garantir le bon
              fonctionnement de vos pipelines en production.
            </p>
          </div>

          {/* Content */}
          <section className="space-y-8">
            {/* Where are results stored */}
            <div>
              <h2 className="text-2xl font-semibold text-[var(--color-text)] mb-4">
                O√π sont stock√©s les r√©sultats d&apos;un pipeline DLT ?
              </h2>
              <p className="text-[var(--color-text-light)] leading-relaxed mb-4">
                Lorsque vous cr√©ez un pipeline DLT, Databricks g√®re
                automatiquement un emplacement de stockage (
                <strong>Storage Location</strong>) qui contient toutes les
                donn√©es produites par le pipeline, ainsi que les m√©tadonn√©es
                n√©cessaires √† son fonctionnement.
              </p>
              <p className="text-[var(--color-text-light)] leading-relaxed mb-4">
                Cet emplacement est configur√© lors de la cr√©ation du pipeline
                et contient plusieurs sous-r√©pertoires organis√©s de mani√®re
                structur√©e.
              </p>
            </div>

            {/* Storage Structure */}
            <div>
              <h2 className="text-2xl font-semibold text-[var(--color-text)] mb-4">
                Structure du stockage DLT
              </h2>
              <p className="text-[var(--color-text-light)] leading-relaxed mb-4">
                Le r√©pertoire de stockage d&apos;un pipeline DLT est organis√©
                comme suit :
              </p>
              <div className="bg-gray-50 border border-gray-200 rounded-lg p-5 font-mono text-sm text-[var(--color-text)] mb-4">
                <p className="mb-1">üìÇ pipeline_storage_location/</p>
                <p className="mb-1 ml-4">
                  üìÇ <strong>system/</strong>
                </p>
                <p className="mb-1 ml-8">üìÑ event_log (journal des √©v√©nements)</p>
                <p className="mb-1 ml-8">üìÑ checkpoints (points de reprise streaming)</p>
                <p className="mb-1 ml-4">
                  üìÇ <strong>tables/</strong>
                </p>
                <p className="mb-1 ml-8">üìÑ table_1/ (tables Delta r√©elles)</p>
                <p className="mb-1 ml-8">üìÑ table_2/</p>
                <p className="mb-1 ml-4">
                  üìÇ <strong>autoloader/</strong>
                </p>
                <p className="ml-8">üìÑ schema/ (suivi des sch√©mas Auto Loader)</p>
              </div>
              <ul className="list-disc list-inside space-y-3 text-[var(--color-text-light)] mb-4">
                <li>
                  <strong>system/</strong> : contient l&apos;event log
                  (journal des √©v√©nements du pipeline) et les checkpoints
                  n√©cessaires au traitement incr√©mental.
                </li>
                <li>
                  <strong>tables/</strong> : contient les tables Delta
                  r√©elles produites par le pipeline. Chaque table est stock√©e
                  en tant que table Delta standard.
                </li>
                <li>
                  <strong>autoloader/</strong> : contient les m√©tadonn√©es de
                  suivi des sch√©mas utilis√©es par Auto Loader pour
                  l&apos;√©volution automatique des sch√©mas.
                </li>
              </ul>
            </div>

            {/* Event Log */}
            <div>
              <h2 className="text-2xl font-semibold text-[var(--color-text)] mb-4">
                L&apos;Event Log : journal du pipeline
              </h2>
              <p className="text-[var(--color-text-light)] leading-relaxed mb-4">
                L&apos;<strong>event log</strong> est la source principale
                d&apos;information pour surveiller et diagnostiquer un
                pipeline DLT. Il enregistre tous les √©v√©nements du cycle de
                vie du pipeline : cr√©ation de tables, progression des flux,
                r√©sultats de qualit√© des donn√©es, et bien plus.
              </p>
              <p className="text-[var(--color-text-light)] leading-relaxed mb-4">
                Vous pouvez interroger l&apos;event log directement en SQL
                gr√¢ce √† la fonction <code>event_log()</code> :
              </p>
              <CodeBlock
                language="sql"
                title="Interroger l'event log d'un pipeline"
                code={`-- Consulter tous les √©v√©nements du pipeline
SELECT * FROM event_log("my_pipeline")

-- Filtrer par type d'√©v√©nement
SELECT *
FROM event_log("my_pipeline")
WHERE event_type = 'flow_progress'
ORDER BY timestamp DESC

-- Voir les derniers √©v√©nements
SELECT timestamp, event_type, message
FROM event_log("my_pipeline")
ORDER BY timestamp DESC
LIMIT 20`}
              />

              <InfoBox type="tip" title="event_log() : votre outil principal de surveillance">
                <p>
                  La fonction <code>event_log()</code> est le moyen principal
                  pour surveiller vos pipelines DLT. Elle vous permet de
                  consulter l&apos;historique complet des ex√©cutions, de
                  diagnostiquer les erreurs, et de suivre les m√©triques de
                  qualit√© des donn√©es. Familiarisez-vous avec cette fonction,
                  elle est essentielle pour l&apos;examen de certification.
                </p>
              </InfoBox>
            </div>

            {/* Event Types */}
            <div>
              <h2 className="text-2xl font-semibold text-[var(--color-text)] mb-4">
                Types d&apos;√©v√©nements
              </h2>
              <p className="text-[var(--color-text-light)] leading-relaxed mb-4">
                L&apos;event log contient plusieurs types d&apos;√©v√©nements,
                chacun fournissant des informations sp√©cifiques :
              </p>
              <div className="overflow-x-auto mb-4">
                <table className="w-full border-collapse border border-gray-300 text-sm">
                  <thead>
                    <tr className="bg-gray-100">
                      <th className="border border-gray-300 px-4 py-2 text-left font-semibold text-[var(--color-text)]">
                        Type d&apos;√©v√©nement
                      </th>
                      <th className="border border-gray-300 px-4 py-2 text-left font-semibold text-[var(--color-text)]">
                        Description
                      </th>
                    </tr>
                  </thead>
                  <tbody>
                    <tr>
                      <td className="border border-gray-300 px-4 py-2 font-mono text-sm text-[var(--color-text-light)]">
                        flow_definition
                      </td>
                      <td className="border border-gray-300 px-4 py-2 text-[var(--color-text-light)]">
                        D√©finition des flux de donn√©es dans le pipeline (requ√™tes SQL/Python)
                      </td>
                    </tr>
                    <tr>
                      <td className="border border-gray-300 px-4 py-2 font-mono text-sm text-[var(--color-text-light)]">
                        flow_progress
                      </td>
                      <td className="border border-gray-300 px-4 py-2 text-[var(--color-text-light)]">
                        Progression des flux : nombre de lignes trait√©es, m√©triques de qualit√©
                      </td>
                    </tr>
                    <tr>
                      <td className="border border-gray-300 px-4 py-2 font-mono text-sm text-[var(--color-text-light)]">
                        dataset_definition
                      </td>
                      <td className="border border-gray-300 px-4 py-2 text-[var(--color-text-light)]">
                        D√©finition des jeux de donn√©es (tables, vues) cr√©√©s par le pipeline
                      </td>
                    </tr>
                    <tr>
                      <td className="border border-gray-300 px-4 py-2 font-mono text-sm text-[var(--color-text-light)]">
                        maintenance
                      </td>
                      <td className="border border-gray-300 px-4 py-2 text-[var(--color-text-light)]">
                        Op√©rations de maintenance automatique (OPTIMIZE, VACUUM)
                      </td>
                    </tr>
                  </tbody>
                </table>
              </div>
            </div>

            {/* DAG Visualization */}
            <div>
              <h2 className="text-2xl font-semibold text-[var(--color-text)] mb-4">
                Visualisation du DAG du pipeline
              </h2>
              <p className="text-[var(--color-text-light)] leading-relaxed mb-4">
                DLT g√©n√®re automatiquement un{" "}
                <strong>DAG (Directed Acyclic Graph)</strong> qui repr√©sente
                visuellement les d√©pendances entre toutes les tables du
                pipeline. Ce graphe montre :
              </p>
              <ul className="list-disc list-inside space-y-2 text-[var(--color-text-light)] mb-4">
                <li>Les sources de donn√©es externes</li>
                <li>Les tables interm√©diaires et finales</li>
                <li>Les d√©pendances entre chaque table</li>
                <li>Le statut de chaque table (succ√®s, √©chec, en cours)</li>
                <li>Les m√©triques de qualit√© (expectations) pour chaque table</li>
              </ul>
              <p className="text-[var(--color-text-light)] leading-relaxed mb-4">
                La visualisation du DAG est accessible directement dans
                l&apos;interface Databricks lorsque vous consultez un
                pipeline DLT. C&apos;est un outil puissant pour comprendre la{" "}
                <strong>lign√©e des donn√©es (lineage)</strong> et diagnostiquer
                les probl√®mes.
              </p>
            </div>

            {/* Querying Data Quality */}
            <div>
              <h2 className="text-2xl font-semibold text-[var(--color-text)] mb-4">
                Interroger les m√©triques de qualit√© des donn√©es
              </h2>
              <p className="text-[var(--color-text-light)] leading-relaxed mb-4">
                Les r√©sultats des expectations sont stock√©s dans l&apos;event
                log sous forme de donn√©es JSON imbriqu√©es. Vous pouvez
                extraire ces m√©triques avec des requ√™tes SQL utilisant la
                notation semi-structur√©e (<code>:</code>) :
              </p>
              <CodeBlock
                language="sql"
                title="Extraire les m√©triques de qualit√© des donn√©es"
                code={`SELECT
  details:flow_progress.metrics.num_output_rows AS output_rows,
  details:flow_progress.data_quality.expectations
FROM event_log("my_pipeline")
WHERE event_type = 'flow_progress'`}
              />

              <CodeBlock
                language="sql"
                title="Analyse d√©taill√©e des r√©sultats de qualit√©"
                code={`-- Extraire les d√©tails des expectations
SELECT
  timestamp,
  details:flow_progress.metrics.num_output_rows AS lignes_produites,
  details:flow_progress.data_quality.expectations.name AS nom_contrainte,
  details:flow_progress.data_quality.expectations.dataset AS table_cible,
  details:flow_progress.data_quality.expectations.passed_records AS enregistrements_valides,
  details:flow_progress.data_quality.expectations.failed_records AS enregistrements_invalides
FROM event_log("my_pipeline")
WHERE event_type = 'flow_progress'
  AND details:flow_progress.data_quality IS NOT NULL
ORDER BY timestamp DESC`}
              />

              <InfoBox type="info" title="Format des m√©triques de qualit√©">
                <p>
                  Les m√©triques de qualit√© sont stock√©es au format JSON dans
                  la colonne <code>details</code> de l&apos;event log.
                  Utilisez la notation{" "}
                  <code>details:flow_progress.data_quality.expectations</code>{" "}
                  pour acc√©der aux r√©sultats. Chaque expectation contient le
                  nombre d&apos;enregistrements valid√©s (
                  <code>passed_records</code>) et rejet√©s (
                  <code>failed_records</code>).
                </p>
              </InfoBox>
            </div>

            {/* Pipeline Update Results */}
            <div>
              <h2 className="text-2xl font-semibold text-[var(--color-text)] mb-4">
                R√©sultats et historique des mises √† jour
              </h2>
              <p className="text-[var(--color-text-light)] leading-relaxed mb-4">
                Chaque ex√©cution d&apos;un pipeline DLT est appel√©e une{" "}
                <strong>mise √† jour (update)</strong>. L&apos;historique de
                toutes les mises √† jour est conserv√© et accessible dans
                l&apos;interface Databricks. Pour chaque mise √† jour, vous
                pouvez consulter :
              </p>
              <ul className="list-disc list-inside space-y-2 text-[var(--color-text-light)] mb-4">
                <li>Le statut global (succ√®s, √©chec, annul√©)</li>
                <li>La dur√©e d&apos;ex√©cution</li>
                <li>Le nombre de lignes trait√©es par table</li>
                <li>Les r√©sultats des expectations</li>
                <li>Les messages d&apos;erreur en cas d&apos;√©chec</li>
                <li>Le DAG avec le statut de chaque √©tape</li>
              </ul>

              <CodeBlock
                language="sql"
                title="Consulter l'historique des mises √† jour"
                code={`-- Voir les mises √† jour r√©centes du pipeline
SELECT
  id,
  timestamp,
  event_type,
  message
FROM event_log("my_pipeline")
WHERE event_type IN ('update_progress', 'create_update', 'update_completed')
ORDER BY timestamp DESC`}
              />
            </div>

            {/* Cluster Configuration */}
            <div>
              <h2 className="text-2xl font-semibold text-[var(--color-text)] mb-4">
                Configuration du cluster DLT
              </h2>
              <p className="text-[var(--color-text-light)] leading-relaxed mb-4">
                Contrairement aux clusters interactifs classiques, les
                clusters DLT sont{" "}
                <strong>enti√®rement g√©r√©s par Databricks</strong>. Vous
                n&apos;avez pas √† cr√©er ou configurer manuellement un cluster
                pour ex√©cuter un pipeline DLT.
              </p>
              <p className="text-[var(--color-text-light)] leading-relaxed mb-4">
                DLT g√®re automatiquement :
              </p>
              <ul className="list-disc list-inside space-y-2 text-[var(--color-text-light)] mb-4">
                <li>Le provisionnement et le d√©marrage du cluster</li>
                <li>Le dimensionnement automatique (autoscaling)</li>
                <li>L&apos;arr√™t du cluster apr√®s l&apos;ex√©cution (en mode Production)</li>
                <li>La configuration optimale pour les charges de travail DLT</li>
              </ul>

              <InfoBox type="important" title="DLT g√®re ses propres clusters">
                <p>
                  Vous ne pouvez pas utiliser un cluster interactif existant
                  pour ex√©cuter un pipeline DLT. DLT provisionne et g√®re ses
                  propres clusters automatiquement. Vous pouvez cependant
                  configurer certains param√®tres comme le type d&apos;instance,
                  le nombre minimum/maximum de workers, et les politiques de
                  cluster.
                </p>
              </InfoBox>
            </div>

            {/* Lineage */}
            <div>
              <h2 className="text-2xl font-semibold text-[var(--color-text)] mb-4">
                Comprendre la lign√©e des donn√©es (Lineage)
              </h2>
              <p className="text-[var(--color-text-light)] leading-relaxed mb-4">
                La <strong>lign√©e des donn√©es (data lineage)</strong> d√©crit
                le parcours des donn√©es depuis leur source jusqu&apos;√† leur
                destination finale. Dans DLT, la lign√©e est automatiquement
                trac√©e gr√¢ce aux r√©f√©rences <code>LIVE.</code> entre les
                tables.
              </p>
              <p className="text-[var(--color-text-light)] leading-relaxed mb-4">
                Le DAG du pipeline est une repr√©sentation visuelle directe de
                cette lign√©e. Il vous permet de :
              </p>
              <ul className="list-disc list-inside space-y-2 text-[var(--color-text-light)] mb-4">
                <li>
                  <strong>Tracer l&apos;impact</strong> : identifier toutes
                  les tables affect√©es par un changement en amont
                </li>
                <li>
                  <strong>Diagnostiquer les erreurs</strong> : remonter la
                  cha√Æne de d√©pendances pour trouver la source d&apos;un
                  probl√®me
                </li>
                <li>
                  <strong>Documenter le flux</strong> : comprendre comment les
                  donn√©es sont transform√©es √† chaque √©tape
                </li>
              </ul>
            </div>
          </section>

          {/* Quiz */}
          <Quiz
            lessonSlug="4-2-resultats-pipeline"
            title="Quiz ‚Äî R√©sultats du Pipeline"
            questions={quizQuestions}
          />

          {/* Exercices */}
          <LessonExercises
            lessonSlug="4-2-resultats-pipeline"
            exercises={exercises}
          />

          {/* Compl√©tion */}
          <LessonCompleteButton lessonSlug="4-2-resultats-pipeline" />

          {/* Navigation */}
          <div className="flex flex-col sm:flex-row justify-between gap-4 mt-12 pt-8 border-t border-[var(--color-border)]">
            <Link
              href="/modules/4-1-delta-live-tables"
              className="inline-flex items-center gap-2 px-5 py-2.5 border border-gray-300 text-[var(--color-text)] rounded-lg font-medium hover:bg-gray-50 transition-colors"
            >
              <svg
                className="w-4 h-4"
                fill="none"
                stroke="currentColor"
                viewBox="0 0 24 24"
              >
                <path
                  strokeLinecap="round"
                  strokeLinejoin="round"
                  strokeWidth={2}
                  d="M15 19l-7-7 7-7"
                />
              </svg>
              Le√ßon pr√©c√©dente : Delta Live Tables
            </Link>
            <Link
              href="/modules/4-3-orchestration-jobs"
              className="inline-flex items-center gap-2 px-5 py-2.5 bg-[#ff3621] text-white rounded-lg font-medium hover:bg-[#e02e1a] transition-colors"
            >
              Le√ßon suivante : Orchestration avec Jobs
              <svg
                className="w-4 h-4"
                fill="none"
                stroke="currentColor"
                viewBox="0 0 24 24"
              >
                <path
                  strokeLinecap="round"
                  strokeLinejoin="round"
                  strokeWidth={2}
                  d="M9 5l7 7-7 7"
                />
              </svg>
            </Link>
          </div>
        </div>
      </main>
    </div>
  );
}
